#import "@preview/fletcher:0.5.1": node, edge, diagram
// #import "template.typ": conf
#import "template/definitions.typ": *
#import "@preview/arkheion:0.1.0": arkheion
#import "@preview/ctheorems:1.1.3": *
#let definition = thmbox("definition", "Definition", inset: (x: 1.2em, top: 1em))
#let theorem = thmbox("theorem", "Theorem", fill: rgb("#eeffee"))
#import "@preview/numty:0.0.5" as nt
#set cite(form: "prose")
// Color references red
#show  ref: it => {text(fill: maroon)[#it]}

#let theorem = thmbox("theorem", "Theorem", fill: rgb("#eeffee"))
#let proof = thmproof("proof", "Proof")

#set math.equation(numbering: "(1)")
#show math.equation: it => {
  if it.block and not it.has("label") [
    #counter(math.equation).update(v => v - 1)
    #math.equation(it.body, block: true, numbering: none)#label("")
  ] else {
    it
  }  
}

#show: thmrules.with(qed-symbol: $square$)
Let us consider the setting of @ryalenPotentialOutcomes
and their regularity conditions.
Specifically, we will work with an intervention
that specifies the treatment decisions
but not the timing of treatment visits.
We
work with Example 4 of @ryalenPotentialOutcomes, in which
$
    pi^* (phi, t, dif x) = delta_(a_0) (dif x),
$
i.e., treatment is always assigned to $a_0$.
To simplify,
we work without right-censoring and no covariates.
This means that $(N^y, N^a)$, where
$N^y$ denotes the counting process on $[0, T]$ for death
and $N^a$ random measure for treatment on
$[0, T] times {a_0, a_1}$.
For this treatment regime, we see that 
$
    tau^A = inf {t >= 0 | N^a ((0, t] times {a_1}) > 0}.
$
We can associate each of the random measures $N^y$ and $N^a$ with
the random measure
$
    N (dif (t, m, a)) = N^y (dif t) delta_y (dif m) + delta_a (dif m) {N^a (dif (t) times {a_0}) delta_(a_0) (dif m) + N^a (dif (t) times {a_1}) delta_(a_1) (dif m)}.
$
This gives rise to a counting process filtration $(cal(F)_t)_(t >= 0)$
generated by $N$. We can then find that $N$ has the compensator
$
    Lambda (dif (t, m, a)) = Lambda^y (dif t) delta_y (dif m) + delta_a (dif m) {pi_t (cal(F)_(t-)) delta_(a_0) (dif m) +  (1-pi_t (cal(F)_(t-))) delta_(a_1) (dif m)} Lambda^a (dif (t)),
$
where we can choose $pi_t$ to be $cal(F)_t$-predictable.
We are interested in the counterfactual mean outcome $mean(P) [tilde(Y)_t]$,
where $(tilde(Y)_t)_(t >= 0)$ is the counterfactual outcome process
of $Y := N^y$ under the intervention that sets treatment to $a_0$ at all visitation times.
Note the different exchangeability condition compared to @ryalenPotentialOutcomes,
as @ryalenPotentialOutcomes expresses exchangeability through the counting process $bb(1) {tau^A <= dot}$;
this is actually a weaker condition.
Let $(event(k), status(k), treat(k))$
denote the ordered event times, event types, and treatment decisions.
Note that @eq:rytgaard is the same likelihood ratio as in @rytgaardContinuoustimeTargetedMinimum2022.
We also impose the assumption that $N_t := N^y_t + N^a( {(0, t] times {a_0, a_1}})$ does not explode;
we also assume that we work with a version of the compensator
such that $Lambda ({t} times {y, a} times {a_0, a_1}) < oo$ for all $t > 0$.
We may generally also work with a compensator $Lambda$ that fulfills conditions (10.1.11)-(10.1.13) of @last1995marked.

*NOTE:* So the issue is that *Positivity* might not actually hold. If we look at $W (t)$, then it is piecewise constant and only jumps at event times.
If it were generally a likelihood ratio, then it would solve @eq:sde. However, the second term is not generally piecewise constant,
so we have placed restrictions (in this case $V(s, x)$ would have to be purely discontinuous $=>^(?)$ predictable visitation times (note: special case discrete compensator for treatment)).
In that case, local independence cannot even motivate this estimand. 

- *What about pointwise identification*?
- $mean(P) [W (tau)] = 1$ but not necessarily $mean(P) [W (t)] != 1$ for all $t$, so that $W (t)$ is not generally a martingale,
  then it still be possible to reweight as follows $mean(P) [tilde(Y)_tau] = mean(P) [Y_tau W (tau)]$.

- *Might be relevant:* https://pmc.ncbi.nlm.nih.gov/articles/PMC3857358/pdf/nihms529556.pdf

#theorem[
Define
$
    zeta (t, m, a) := bb(1) {m=y} + bb(1) {m=a} (bb(1) {a = a_0})/(pi_t)
$
If _all_ of the following conditions hold:
- *Consistency*: $tilde(Y)_(t) bb(1) {T^a > dot} = Y_(t) bb(1) {T^a > dot} quad P-"a.s."$
- *Exchangeability*:
  Define $cal(H)_t := cal(F)_t or sigma(tilde(Y))$.
  The $P$-$cal(F)_t$ compensator for $N^a$ is also the $P$-$cal(H)_t$ compensator.
- *Positivity*:
  $
      W_(t) := product_(j = 1)^(N_t) ((bb(1) {treat(j) = a_0}) / (pi_(event(j)) (history(j-1))))^(bb(1) {status(j) = a})
  $ <eq:rytgaard>
  fulfills that $integral_0^t W(s -) V(s, m, a) (N (d(s,m, a)) - Lambda (d(s,m, a))$ is a zero mean square-integrable, $P$-$cal(F)_t$-martingale.
Then,
$
    mean(P) [tilde(Y)_t] = mean(P) [Y_t W_(t)]
$
] <thm:identifiabilitymartingale>

#proof[
    We shall use that the likelihood ratio solves a specific stochastic differential equation.
    To this end, we define the random measure, $mu (d (t, m, a)) := zeta (t, m, a) nu (d (t, m, a))$,
    where $nu := Lambda$.
    The likelihood ratio process $L (t)$ given in (10.1.14) of @last1995marked is defined by
    $
        L(t) &= bb(1) {t < T_oo and T_oo (nu)) L_0 product_(n : event(n) <= t) zeta(event(n), status(n), treat(n)) \
             &quad product_(s <= t \ N_(s-) = N_(s)) (1-macron(nu) {s}) / (1-macron(mu) {s}) exp(integral bb(1){s <= t} (1-zeta(s,m, a)) nu^c (d (s, m, a))) \
            &+ bb(1) {t >= T_oo and T_oo (nu)} liminf_(s -> T_oo and T_oo (nu)) L(s).
    $ <eq:lrt>
    Here $T_oo := lim_n T_n$, $T_oo (nu) := inf {t >= 0 | nu ((0, t] times {y, a} times {a_0, a_1}) = oo}$,
    $macron(mu)(dot) := mu(dot times {y, a} times {a_0, a_1})$,
    $macron(nu)(dot) := nu(dot times {y, a} times {a_0, a_1})$,
    $nu^c (dif (s, m, a)) := bb(1) {macron(nu) {s} = 0} nu (d (s, m, a))$, and $L_0 := W (0) = 1$.

    By our assumptions, $T_oo = oo quad P $-a.s. and 
    thus $T_oo (nu) = T_oo = oo$ in view Theorem 4.1.7 (ii) of @last1995marked
    since $macron(nu) {t} < oo$ for all $t > 0$.
    
    Second, note that $macron(nu) = macron(mu)$. This follows since
    $
        macron(mu) (A) &= integral_(A times {y, a} times {a_0, a_1}) zeta(t, m, a) nu (d (t, m, a)) \
            &=integral_(A times {y} times {a_0, a_1}) zeta(t, m, a) nu (d (t, m, a))  + integral_(A times {a} times {a_0, a_1}) zeta(t, m, a) nu (d (t, m, a)) \
    &=integral_(A times {y} times {a_0, a_1}) 1 nu (d (t, m, a))  + integral_(A times {a} times {a_0, a_1}) ((bb(1) {a=a_0})/pi_t)  nu (d (t, m, a)) \
            &=nu (A times {y} times {a_0, a_1})  + integral_(A) Lambda^a (d t)\
            &=nu (A times {y} times {a_0, a_1}) + nu (A times {a} times {a_0, a_1}) \
            &=nu (A times {y, a} times {a_0, a_1}) = macron(nu) (A).
    $
    Thus
    $
        product_(s <= t \ N_(s-) = N_(s)) (1-macron(nu) {s}) / (1-macron(mu) {s}) exp(integral bb(1){s <= t} (1-zeta(s,m, a)) nu^c (d (s, m, a))) = 1,
    $
    and hence
    $
        L(t) &= product_(n : event(n) <= t) zeta(event(n), status(n), treat(n)) \
            &=^"def."W (t).
    $
    Let $V(s,m, a) = zeta(s,m, a) - 1 + (macron(nu) {s}-macron(mu) {s})/(1-macron(mu) {s}) = zeta(s,m, a)-1$.
    $L (t)$ will fulfill that
    $
        L (t) = L_0 + integral bb(1) {s <= t} V(s,m, a) L(s-) [Phi (d(s,m, a)) - nu (d(s,m, a))] \
    $ 
    if
    $
        mean(P) [L_0] = 1, \
        macron(mu) {t} <= 1, \
        macron(mu) {t} = 1 " if " macron(nu) {t} = 1, \
        macron(mu) [T_oo and T_oo (mu)] = 0 " and " macron(nu) [T_oo and T_oo (nu)] = 0.
    $ <eq:conditionstheorem1022>
    by Theorem 10.2.2 of @last1995marked.
    These can be easily verified.
    
    // The first condition holds by positivity. The second condition holds by the specific choice
    // of compensator since $sum_x cumhazard(k, x, {t}) <= 1$ for all $k = 1, dots, K$ and $t in (0, tauend]$ (Theorem A5.9 of @last1995marked).
    // The third holds since $macron(mu) = macron(nu)$ and the fourth holds since $T_oo = T_oo (nu) = T_oo (mu) = oo$.
    
    Thus,
    $
        W(t) = 1 + integral_0^t W(s -) V(s, m, a) (Phi (d(s,m, a)) - nu (d(s,m, a)).
    $ <eq:sde>
    and it follows that $integral_0^t W(s -) V(s, m, a) (Phi (d(s,m, a)) - nu (d(s,m, a))$ is a zero mean$P$-$cal(H)_t$-martingale.
    From this, we see that $integral_0^t tilde(Y)_(t) W_(s-) V(s, m, a) (Phi (d(s,m, a)) - nu (d(s,m, a))$ is also a zero mean $P$-$cal(H)_t$-martingale.
    This implies that
    $
        mean(P) [Y_t W_(t)] &=^"(consistency)" mean(P) [tilde(Y)_t W_t] \
            &= mean(P) [tilde(Y)_t] + mean(P) [integral_0^t tilde(Y)_(t) W_(s-) V(s, m, a) (Phi (d(s,m, a)) - nu (d(s,m, a))] \
                &= mean(P) [tilde(Y)_t].
    $
]

#bibliography("references/ref.bib",style: "apa")
