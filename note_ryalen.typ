#import "@preview/fletcher:0.5.1": node, edge, diagram
// #import "template.typ": conf
#import "template/definitions.typ": *
#import "@preview/arkheion:0.1.0": arkheion
#import "@preview/ctheorems:1.1.3": *
#let definition = thmbox("definition", "Definition", inset: (x: 1.2em, top: 1em))
#let theorem = thmbox("theorem", "Theorem", fill: rgb("#eeffee"))
#import "@preview/numty:0.0.5" as nt
#set cite(form: "prose")
// Color references red
#show  ref: it => {text(fill: maroon)[#it]}

#let theorem = thmbox("theorem", "Theorem", fill: rgb("#eeffee"))
#let proof = thmproof("proof", "Proof")

#set math.equation(numbering: "(1)")
#show math.equation: it => {
  if it.block and not it.has("label") [
    #counter(math.equation).update(v => v - 1)
    #math.equation(it.body, block: true, numbering: none)#label("")
  ] else {
    it
  }  
}

#show: thmrules.with(qed-symbol: $square$)

= A causal interpretation of target parameter in continuous time of @rytgaardContinuoustimeTargetedMinimum2022

Let us consider a setting similar to the one of @ryalenPotentialOutcomes.
Specifically, we will work with an intervention
that specifies the treatment decisions
but not the timing of treatment visits.
We consider death as the outcome of interest
and are interested in the probability of death,
had had we followed the regime of always treating.
To simplify,
we work without right-censoring, no covariates,
and compliance to treatment at time $0$.
Let $(Omega, cal(F), P)$ be a probability space.
and consider $(N^y, N^a)$,
where
- $N^y$ is a counting process on $[0, T]$ for death.
- $N^a$ is a random measure for treatment on $[0, T] times {1, 0}$, where $1$ denotes treatment and $0$ no treatment.

We consider the filtration generated by $(N^y, N^a)$ and denote it by $(cal(F)_t)_(t >= 0)$,
i.e.,
$
    cal(F)_t := sigma(N^y (dif s), N^a (dif s times {x}) | s in (0, t], x in {0, 1}).
$
Further, we assume that
- $N^y$ and $N^a ({(0, t] times {1, 0}})$ do not jump at the same time.
- $M^y = N^y - Lambda^y$ denotes their $P$-$cal(F)_t$ (local) martingale,
  where $Lambda^y$ is the $P$-$cal(F)_t$-compensator of $N^y$.
- $M^a (dif t times {x}) = N^a (dif t times {x}) - (pi_t)^(bb(1) {x=1}) (1-pi_t)^(bb(1) {x=0}) Lambda^a (dif t)$
  is the $P$-$cal(F)_t$ (local) martingale for $x in {1, 0}$,
  where $pi_t$ is the $cal(F)_t$-predictable probability of treatment at time $t$ (mark probability) and
  $Lambda^a (dif t)$ is the total $P$-$cal(F)_t$-compensator of $N^a (dif t times dif x)$.

For this treatment regime, we see that 
$
    tau^A = inf {t >= 0 | N^a ((0, t] times {0}) > 0}.
$
// We can associate each of the random measures $N^y$ and $N^a$ with
// the random measure
// $
//     N (dif (t, m, a)) = N^y (dif t) delta_y (dif m) + delta_a (dif m) {N^a (dif (t) times {1}) delta_(1) (dif m) + N^a (dif (t) times {0}) delta_(0) (dif m)}.
// $
// We can then find that $N$ has the $P$-$cal(F)_t$-compensator,
// $
//     Lambda (dif (t, m, a)) = Lambda^y (dif t) delta_y (dif m) + delta_a (dif m) {pi_t (cal(F)_(t-)) delta_(1) (dif m) +  (1-pi_t (cal(F)_(t-))) delta_(0) (dif m)} Lambda^a (dif (t)),
// $
//where we can choose $pi_t$ to be $cal(F)_t$-predictable.
We are interested in the counterfactual mean outcome $mean(P) [tilde(Y)_t]$,
where $(tilde(Y)_t)_(t >= 0)$ is the counterfactual outcome process
of $Y := N^y$ under the intervention that sets treatment to $1$ at all visitation times.
Note the different exchangeability condition compared to @ryalenPotentialOutcomes,
as @ryalenPotentialOutcomes expresses exchangeability through the counting process $bb(1) {tau^A <= dot}$.
//this appears to me to be a weaker condition (?).
Let $(event(k), status(k), treat(k))$
denote the ordered event times, event types, and treatment decisions at event $k$.
Note that @eq:rytgaard is the same likelihood ratio as in @rytgaardContinuoustimeTargetedMinimum2022.
We also impose the assumption that $N_t := N^y_t + N^a ( {(0, t] times {1, 0}})$ does not explode;
we also assume that we work with a version of the compensator
such that $Lambda ({t} times {y, a} times {1, 0}) < oo$ for all $t > 0$.
We may generally also work with a compensator $Lambda$ that fulfills conditions (10.1.11)-(10.1.13) of @last1995marked.
Let $pi_(event(k))^* (history(k-1))$ denote the interventional probability,
which in this case we take to be $1$.
In this case,
$
    pi_t &= sum_k bb(1) {event(k-1) < t < event(k)} pi_(event(k)) (history(k-1)) \
    pi^*_t &= sum_k bb(1) {event(k-1) < t < event(k)} pi^*_(event(k)) (history(k-1)) = 1.
$

// - *Might be relevant:* https://pmc.ncbi.nlm.nih.gov/articles/PMC3857358/pdf/nihms529556.pdf

#theorem[
Define
$
    zeta (t, m, a) := bb(1) {m=y} + bb(1) {m=a} (bb(1) {a = 1})/(pi_t)
$
If _all_ of the following conditions hold:
- *Consistency*: $tilde(Y)_(t) bb(1) {tau^a > dot} = Y_(t) bb(1) {tau^a > dot} quad P-"a.s."$
- *Exchangeability*:
  Define $cal(H)_t := cal(F)_t or sigma(tilde(Y))$.
  The $P$-$cal(F)_t$ compensator for $N^a$ is also the $P$-$cal(H)_t$ compensator.
- *Positivity*: Let $N^(a x) (dif t) := N^a (dif (t) times {x})$ for $x in {1, 0}$.
  $
      W (t) := product_(j = 1)^(N_t) (((pi^*_(event(j)) (history(j-1))) / (pi_(event(j)) (history(j-1))))^(bb(1) {treat(k) = 1}) ((1-pi^*_(event(j)) (history(j-1))) / (1-pi_(event(j)) (history(j-1))))^(bb(1) {treat(k) = 0}))^(bb(1) {status(j) = a}) 
  $ <eq:rytgaard>
  fulfills that
  $
      integral_0^t W(s -) ( pi^*_(s) / pi_(s) - 1) N^(a 1) (dif s),
      integral_0^t W(s -) ((1-pi^*_(s)) / (1-pi_(s)) - 1) N^(a 0) (dif s),
  $
  are zero mean square-integrable, $P$-$cal(F)_t$-martingales.
Then,
$
    mean(P) [tilde(Y)_t] = mean(P) [Y_t W (t)]
$
] <thm:identifiabilitymartingale>

#proof[
    We shall use that the likelihood ratio solves a specific stochastic differential equation.
    To this end, note that
    $
        &W(t) \
            &= product_(s <= t) (1 + ((pi_s^*)/(pi_s) - 1) N^(a 1) (dif s) + ((1-pi_s^*)/(1-pi_s) - 1) N^(a 0) (dif s)) \
            &= product_(s <= t) (1 + ((pi_s^*)/(pi_s) - 1) N^(a 1) (dif s) + ((1-pi_s^*)/(1-pi_s) - 1) N^(a 0) (dif s) - (pi_s^* - pi_s) Lambda^(a) (d s) - (pi_s - pi_s^*) Lambda^(a) (d s)) \
            &= product_(s <= t) (1 + ((pi_s^*)/(pi_s) - 1) N^(a 1) (dif s) + ((1-pi_s^*)/(1-pi_s) - 1) N^(a 0) (dif s) - (pi_s^* - pi_s) / pi_s Lambda^(a 1) (d s) - (pi_s - pi_s^*) / (1-pi_s) Lambda^(a 0) (d s)) \
            &= product_(s <= t) (1 + ((pi_s^*)/(pi_s) - 1) M^(a 1) (dif s) + ((1-pi_s^*)/(1-pi_s) - 1) M^(a 0) (dif s)).        
    $
        
    Thus, by properties of the product integral (e.g., Theorem II.6.1 of @andersenStatisticalModelsBased1993),
    $
        W(t) = 1 + integral_0^t W(s -) ((pi_s^*)/(pi_s) - 1) M^(a 1) (dif s) + integral_0^t W(s-) ((1-pi_s^*)/(1-pi_s) - 1) M^(a 0) (dif s).
    $ <eq:sde>
    We have that
    $
        zeta_t := integral_0^t W(s -) ((pi_s^*)/(pi_s) - 1) M^(a 1) (dif s) + integral_0^t W(s-) ((1-pi_s^*)/(1-pi_s) - 1) M^(a 0) (dif s)
    $ is a zero mean$P$-$cal(H)_t$-martingale.
    From this, we see that $integral_0^t tilde(Y)_(t) zeta (dif s)$ is also a zero mean $P$-$cal(H)_t$-martingale.
    This implies that
    $
        mean(P) [Y_t W (t)] &=^(*) mean(P) [tilde(Y)_t W (t)] = mean(P) [tilde(Y)_t] + mean(P) [integral_0^t tilde(Y)_(t) zeta (dif s)] = mean(P) [tilde(Y)_t],
    $
    where in $*$ we used consistency by noting that $W (t) != 0$ if and only if $tau^a > t$.
]

#bibliography("references/ref.bib",style: "apa")
